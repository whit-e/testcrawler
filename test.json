[
{"title": "Webcrawler", "content": "\n\n\n\nWebcrawler \naus Wikipedia, der freien Enzyklop\u00e4die \n\n\t\t\t\t\tWechseln zu:\t\t\t\t\tNavigation, \t\t\t\t\tSuche\n\n\n\n \n\n Dieser Artikel behandelt Webseitenanalyse-Programme, f\u00fcr die gleichnamige Suchmaschine siehe WebCrawler.\n\nEin Webcrawler (auch Spider, Searchbot oder Robot) ist ein Computerprogramm, das automatisch das World Wide Web durchsucht und Webseiten analysiert. Webcrawler werden vor allem von Suchmaschinen zur Indexierung von Webseiten eingesetzt. Weitere Anwendungen sind das Sammeln von Web-Feeds, E-Mail-Adressen oder von anderen Informationen.\nWebcrawler sind eine spezielle Art von Bots, also Computerprogrammen, die weitgehend automatisch sich wiederholenden Aufgaben nachgehen.\n\nInhaltsverzeichnis\n\n1 Geschichte\n2 Technik\n3 Ausschluss von Webcrawlern\n4 Probleme\n5 Arten\n6 Siehe auch\n7 Einzelnachweise\n8 Weblinks\n\n\nGeschichte[Bearbeiten | Quelltext bearbeiten]\nDer erste Webcrawler war 1993 der World Wide Web Wanderer, der das Wachstum des Internets messen sollte. 1994 startete mit WebCrawler die erste \u00f6ffentlich erreichbare WWW-Suchmaschine mit Volltextindex. Von dieser stammt auch der Name Webcrawler f\u00fcr solche Programme. Da die Anzahl der Suchmaschinen rasant wuchs, gibt es heute eine Vielzahl von unterschiedlichen Webcrawlern. Diese erzeugen bis zu 40\u00a0% des gesamten Internettraffics.[1]\n\nTechnik[Bearbeiten | Quelltext bearbeiten]\n Struktur von Webcrawlern\nWie beim Internetsurfen gelangt ein Webcrawler \u00fcber Hyperlinks von einer Webseite zu weiteren URLs. Dabei werden alle aufgefundenen Adressen gespeichert und der Reihe nach besucht. Die neu gefundenen Hyperlinks werden zur Liste aller URLs hinzugef\u00fcgt. Auf diese Weise k\u00f6nnen theoretisch alle verlinkten und nicht f\u00fcr Webcrawler gesperrten Seiten des WWW gefunden werden. In der Praxis wird jedoch oft eine Auswahl getroffen, der Prozess irgendwann beendet und von vorne begonnen. Je nach Aufgabe des Webcrawlers wird der Inhalt der gefundenen Webseiten beispielsweise mittels Indexierung ausgewertet und gespeichert, um ein sp\u00e4teres Suchen in den so gesammelten Daten zu erm\u00f6glichen.\n\nAusschluss von Webcrawlern[Bearbeiten | Quelltext bearbeiten]\nMit Hilfe des Robots Exclusion Standards kann ein Webseitenbetreiber in der Datei robots.txt und in bestimmten Meta-Tags im HTML-Header einem Webcrawler mitteilen, welche Seiten er indexieren soll und welche nicht, sofern sich der Webcrawler an das Protokoll h\u00e4lt. Zur Bek\u00e4mpfung unerw\u00fcnschter Webcrawler gibt es auch spezielle Webseiten, sogenannte Teergruben, die den Webcrawlern falsche Informationen liefern und diese zus\u00e4tzlich stark ausbremsen.\n\nProbleme[Bearbeiten | Quelltext bearbeiten]\nEin Gro\u00dfteil des gesamten Internets wird von Webcrawlern und damit auch von \u00f6ffentlichen Suchmaschinen nicht erfasst, da viele Inhalte nicht \u00fcber einfache Links, sondern beispielsweise nur \u00fcber Suchmasken und zugangsbeschr\u00e4nkte Portale erreichbar sind. Man spricht bei diesen Bereichen auch vom \u201eDeep Web\u201c. Au\u00dferdem stellt die st\u00e4ndige Ver\u00e4nderung des Webs sowie die Manipulation der Inhalte (Cloaking) ein Problem dar.\n\nArten[Bearbeiten | Quelltext bearbeiten]\nThematisch fokussierte Webcrawler werden als focused crawlers bzw. fokussierte Webcrawler bezeichnet. Die Fokussierung der Web-Suche wird einerseits durch die Klassifizierung einer Webseite an sich und die Klassifizierung der einzelnen Hyperlinks realisiert. Dadurch findet der fokussierte Crawler den besten Weg durch das Web und indexiert nur (f\u00fcr ein Thema bzw. eine Dom\u00e4ne) relevante Bereiche des Webs. H\u00fcrden bei der praktischen Umsetzung derartiger Webcrawler sind vor allem nicht-verlinkte Teilbereiche und das Training der Klassifizierer.[2]\nWebcrawler werden auch zum Data-Mining und zur Untersuchung des Internets (Webometrie) eingesetzt und m\u00fcssen nicht zwangsl\u00e4ufig auf das WWW beschr\u00e4nkt sein.\nEine Sonderform der Webcrawler sind E-Mail-Harvester (\u201eHarvester\u201c f\u00fcr \u201eErntemaschine\u201c). Diese Bezeichnung wird f\u00fcr Software verwendet, die das Internet (WWW, Usenet usw.) nach E-Mail-Adressen absucht und diese \u201eerntet\u201c. So werden elektronische Adressen gesammelt und k\u00f6nnen danach vermarktet werden. Die Folge sind i.\u00a0d.\u00a0R., vor allem aber bei Spambots, Werbe-E-Mails (Spam). Daher wird von der fr\u00fcher g\u00e4ngigen Praxis, auf Webseiten E-Mail-Adressen als Kontaktm\u00f6glichkeit per mailto:-Link anzugeben, immer h\u00e4ufiger Abstand genommen; manchmal wird versucht, die Adressen durch den Einschub von Leerzeichen oder W\u00f6rtern f\u00fcr die Bots unlesbar zu machen. So wird a@example.com zu a (at) example (dot) com. Die meisten Bots k\u00f6nnen solche Adressen allerdings erkennen. Eine ebenfalls beliebte Methode ist, die E-Mail-Adresse in eine Grafik einzubetten. Die E-Mail-Adresse ist dadurch nicht als Zeichenkette im Quelltext der Webseite vorhanden und somit f\u00fcr den Bot nicht als Textinformation auffindbar. Das hat f\u00fcr den Benutzer jedoch den Nachteil, dass er die E-Mail-Adresse nicht durch \u201eAnklicken\u201c bedienerfreundlich in sein E-Mail-Programm zum Versand \u00fcbernehmen kann, sondern die Adresse abschreiben muss. Viel gravierender ist jedoch, dass die Seite damit nicht mehr barrierefrei ist und sehbehinderte Menschen genauso wie Bots ausgegrenzt werden.\nEin weiterer Verwendungszweck von Webcrawlern ist das Auffinden von urheberrechtlich gesch\u00fctzten Inhalten im Internet.\n\nSiehe auch[Bearbeiten | Quelltext bearbeiten]\n Wrapper (Informationsextraktion)\nEinzelnachweise[Bearbeiten | Quelltext bearbeiten]\n\n\u2191 X. Yuan, M. H. MacGregor, J. Harms: An efficient scheme to remove crawler traffic from the Internet. Computer Communications and Networks, 2002. Proceedings. Eleventh International Conference on Communications and Networks\n\n\u2191 Sotiris Batsakis, Euripides G. M. Petrakis, Evangelos Milios: Improving the Performance of Focused Web Crawlers. 9. April 2012. (englisch)\n\n\nWeblinks[Bearbeiten | Quelltext bearbeiten]\n The Web Robots Pages (englisch)\n Webcrawling \u2013 Die Erschlie\u00dfung des Webs, Ronny Harbich, 2008.\nNormdaten\u00a0(Sachbegriff):  GND: 4796298-7 (AKS) \n\n\n\n\n \n\t\t\t\t\t\tAbgerufen von \u201ehttps://de.wikipedia.org/w/index.php?title=Webcrawler&oldid=171630031\u201c\t\t\t\t\t\nKategorien: World Wide WebUsenetDownload-Manager \n\n"}
]